{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from models.simplepose import SimplePose\n",
    "from models.datasets.lsp import LSPet, LSP\n",
    "\n",
    "import numpy as np\n",
    "from vis import show_pose\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/lsp-train loaded successfully.\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/lsp-train\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "batch_size = 10  # Кол-во записей в пакете, передаваемом нейросети за раз\n",
    "image_size = (128, 128)  # Размер входного изображения\n",
    "# hmap_size = 32\n",
    "\n",
    "tform = transforms.Compose([  # Объявление трансформации для исходных изображений:\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(image_size),  # Рескейл изображений до заданного размера\n",
    "    transforms.ToTensor(),  # Приведения исходного изображения к формату тензора\n",
    "    # transforms.Normalize([0.5], [0.5]),\n",
    "])\n",
    "\n",
    "# lsp = LSPet('./models/datasets/lspet_dataset/', transform, image_size)\n",
    "# lsp_loader = DataLoader(lsp, batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "dl_train = deeplake.load(\"hub://activeloop/lsp-train\")  # Получение данных\n",
    "# Создание объекта, позволяющего итерировать данные\n",
    "lsp_train_loader = dl_train.pytorch(\n",
    "    tensors=[\"images\", \"keypoints\"],\n",
    "    decode_method={'images': 'numpy'},\n",
    "    transform={'images': tform, 'keypoints': None},\n",
    "    batch_size=batch_size, shuffle=True, num_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss(torch.nn.Module):  # Лосс-функция средний квадрат ошибок\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MSELoss, self).__init__()\n",
    "\n",
    "    def forward(self, output, joints):\n",
    "        output = output.view(output.shape[0], 14, 2)\n",
    "        joints = joints[:, :, :-1]\n",
    "        return torch.sum((output - joints) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = SimplePose().cuda()  # Инициализация модели и её выгрузка на ГПУ\n",
    "model.load_state_dict(torch.load('./weights/simplepose9.weights'))  # Загрузка pre-trained weights\n",
    "criterion = MSELoss().cuda()  # Инициализация объекта лосс-функции и его выгрузка на ГПУ\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)  # Инициализация оптимизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add network into tensorboard\n",
    "# data = next(iter(lsp_train_loader))\n",
    "#\n",
    "# # Создание тензорборда\n",
    "# tb = SummaryWriter()\n",
    "# tb.add_graph(model, data[0].cuda())\n",
    "# # tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   3%|▎         | 55.1M/1.91G [00:12<06:59, 4.74MB/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Batch: 0, Loss: 909493.8125, Epoch: 0\n",
      "Batch: 10, Loss: 791956.75, Epoch: 0\n",
      "Batch: 20, Loss: 714106.875, Epoch: 0\n",
      "Batch: 30, Loss: 446182.0, Epoch: 0\n",
      "Batch: 40, Loss: 550399.375, Epoch: 0\n",
      "Batch: 50, Loss: 554523.8125, Epoch: 0\n",
      "Batch: 60, Loss: 409422.5625, Epoch: 0\n",
      "Batch: 70, Loss: 604665.6875, Epoch: 0\n",
      "Batch: 80, Loss: 360482.0625, Epoch: 0\n",
      "Batch: 90, Loss: 353916.625, Epoch: 0\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(1):\n",
    "    for batch, batch_data in enumerate(lsp_train_loader):\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        input_image = batch_data['images'].cuda()\n",
    "        joints_hmap = batch_data['keypoints'].cuda()\n",
    "        # mask = batch_data[3].cuda()\n",
    "\n",
    "        prediction = model(input_image)\n",
    "\n",
    "        loss = criterion(prediction, joints_hmap)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # Tensorboard\n",
    "        # tb.add_scalar('Loss', loss, 1250*epoch + batch)\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print('Batch: {}, Loss: {}, Epoch: {}'.format(batch, loss.data, epoch))\n",
    "            # Add keypoints loss of testing data\n",
    "\n",
    "    # # Tensorboard\n",
    "    # for name, weight in model.named_parameters():\n",
    "    #     tb.add_histogram(name, weight, epoch)\n",
    "    #     tb.add_histogram(f'{name}.grad', weight.grad, epoch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.save(model.state_dict(), './weights/simplepose{}.weights'.format(epoch))\n",
    "\n",
    "# tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/lsp-test loaded successfully.\n",
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/lsp-test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   3%|▎         | 55.7M/1.91G [00:12<06:56, 4.78MB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "pic should be 2/3 dimensional. Got 4 dimensions.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m test_image, \u001B[38;5;241m*\u001B[39m_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(lsp_test_loader))\n\u001B[1;32m     14\u001B[0m test_predictions \u001B[38;5;241m=\u001B[39m model(test_image[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mcuda())\n\u001B[0;32m---> 15\u001B[0m \u001B[43mshow_pose\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_image\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_predictions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/coding/pycharm/pytorch_course_animal_pose_estimation/human_pose-master/vis.py:12\u001B[0m, in \u001B[0;36mshow_pose\u001B[0;34m(image, pose, ignore_joints)\u001B[0m\n\u001B[1;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m20\u001B[39m))\n\u001B[1;32m     11\u001B[0m ax1 \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m121\u001B[39m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mequal\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 12\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     13\u001B[0m pose \u001B[38;5;241m=\u001B[39m pose\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m14\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, j \u001B[38;5;129;01min\u001B[39;00m [(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m), (\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m), (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m), (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m), (\u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m7\u001B[39m), (\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m8\u001B[39m), (\u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m10\u001B[39m), (\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m11\u001B[39m), (\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m12\u001B[39m), (\u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m12\u001B[39m), (\u001B[38;5;241m12\u001B[39m, \u001B[38;5;241m13\u001B[39m), (\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m12\u001B[39m), (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m12\u001B[39m)]:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl_pytorch_project/lib/python3.10/site-packages/torchvision/transforms/transforms.py:227\u001B[0m, in \u001B[0;36mToPILImage.__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;124;03m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    225\u001B[0m \n\u001B[1;32m    226\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_pil_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl_pytorch_project/lib/python3.10/site-packages/torchvision/transforms/functional.py:263\u001B[0m, in \u001B[0;36mto_pil_image\u001B[0;34m(pic, mode)\u001B[0m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pic, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mndimension() \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m}:\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpic should be 2/3 dimensional. Got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpic\u001B[38;5;241m.\u001B[39mndimension()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m dimensions.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m pic\u001B[38;5;241m.\u001B[39mndimension() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m    266\u001B[0m         \u001B[38;5;66;03m# if 2D image, add channel dimension (CHW)\u001B[39;00m\n\u001B[1;32m    267\u001B[0m         pic \u001B[38;5;241m=\u001B[39m pic\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: pic should be 2/3 dimensional. Got 4 dimensions."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 2000x2000 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lsp_test = LSP('./dataset/lsp_dataset/', transform, image_size)\n",
    "\n",
    "dl_test = deeplake.load(\"hub://activeloop/lsp-test\")\n",
    "lsp_test_loader = dl_test.pytorch(\n",
    "    tensors=[\"images\", \"keypoints\"],\n",
    "    decode_method={'images': 'numpy'},\n",
    "    transform={'images': tform, 'keypoints': None},\n",
    "    batch_size=batch_size, shuffle=True, num_workers=3\n",
    ")\n",
    "#\n",
    "# test_image, *_ = lsp_test_loader.__getitem__(np.random.randint(len(lsp_test_loader)))\n",
    "# test_image, *_ = lsp_test_loader[np.random.randint(len(lsp_test_loader))]\n",
    "test_image, *_ = next(iter(lsp_test_loader))\n",
    "test_predictions = model(test_image[0].cuda())\n",
    "show_pose(test_image, test_predictions.squeeze().cpu().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpytorchcondaf04cb2303bb94659b54446e023c3cb62",
   "display_name": "Python 3.8.2 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

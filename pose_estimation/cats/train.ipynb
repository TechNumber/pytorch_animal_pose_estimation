{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "import conf.config_dataclasses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lit_module:\n",
      "  _target_: models.lightning_hmap_estimator.LitHMapEstimator\n",
      "  _recursive_: false\n",
      "model:\n",
      "  init:\n",
      "    _target_: models.conv_pose_machines.ConvolutionalPoseMachines\n",
      "    _recursive_: false\n",
      "  norm_layer: torch.nn.LayerNorm\n",
      "  act_layer: torch.nn.GELU\n",
      "  pool_layer: torch.nn.MaxPool2d\n",
      "  drop_rate: 0.3\n",
      "  n_substages: 6\n",
      "  n_base_ch: 128\n",
      "  img_feat_ch: 64\n",
      "loss:\n",
      "  _target_: torch.nn.MSELoss\n",
      "  reduction: sum\n",
      "metric:\n",
      "  _target_: utils.metrics.PCK\n",
      "  thr: 0.1\n",
      "optimizer:\n",
      "  _target_: torch.optim.Adam\n",
      "  lr: 1.0e-05\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.OneCycleLR\n",
      "  max_lr: 1.0e-05\n",
      "  total_steps: null\n",
      "dataset:\n",
      "  init:\n",
      "    _target_: datasets.cats_datamodule.AKDDataModule\n",
      "    _recursive_: false\n",
      "  data_dir: ./data\n",
      "  heatmap_size: 45\n",
      "  produce_visibility: true\n",
      "  subset_size: 1500\n",
      "  batch_size: 8\n",
      "  shuffle: true\n",
      "  num_workers: 4\n",
      "  n_keypoints: 16\n",
      "  include_bground_map: false\n",
      "trainer:\n",
      "  max_epochs: 500\n",
      "  accumulate_grad_batches: 2\n",
      "  accelerator: auto\n",
      "  deterministic: false\n",
      "logger:\n",
      "  _target_: pytorch_lightning.loggers.wandb.WandbLogger\n",
      "  project: animal_pose_estimation\n",
      "  name: null\n",
      "  id: null\n",
      "  resume: null\n",
      "train_augmentations:\n",
      "  all:\n",
      "    flip:\n",
      "      _target_: utils.transforms.RandomFlip\n",
      "      ver_cv: 0.5\n",
      "      hor_cv: 0.5\n",
      "    ratio_crop:\n",
      "      _target_: utils.transforms.RandomRatioCrop\n",
      "      max_top_offset: 0.1\n",
      "      max_left_offset: 0.1\n",
      "      min_crop_height: 0.9\n",
      "      min_crop_width: 0.9\n",
      "    rotation:\n",
      "      _target_: utils.transforms.RandomRotation\n",
      "      degrees:\n",
      "      - -30\n",
      "      - 30\n",
      "  image:\n",
      "    resize:\n",
      "      _target_: torchvision.transforms.Resize\n",
      "      size:\n",
      "      - 368\n",
      "      - 368\n",
      "    to_tensor:\n",
      "      _target_: torchvision.transforms.ToTensor\n",
      "  target: null\n",
      "test_augmentations:\n",
      "  all: null\n",
      "  image:\n",
      "    resize:\n",
      "      _target_: torchvision.transforms.Resize\n",
      "      size:\n",
      "      - 368\n",
      "      - 368\n",
      "    to_tensor:\n",
      "      _target_: torchvision.transforms.ToTensor\n",
      "  target: null\n",
      "callbacks:\n",
      "  model_checkpoint:\n",
      "    _target_: pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint\n",
      "    dirpath: checkpoints\n",
      "    filename: ${class_name:${model.init._target_}}-{epoch}-{step}-{val_metric:.2f}-{val_loss:.2f}\n",
      "    save_top_k: 2\n",
      "    save_last: true\n",
      "    monitor: val_metric\n",
      "    mode: max\n",
      "  lr_monitor:\n",
      "    _target_: pytorch_lightning.callbacks.LearningRateMonitor\n",
      "seed: 37\n",
      "checkpoint_path: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=None, config_path=\"../../conf\"):\n",
    "    cfg = compose(config_name='config')\n",
    "print(OmegaConf.to_yaml(cfg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 37\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mtechnumber\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.14.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>./wandb/run-20230317_123821-8pd297a9</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/technumber/animal_pose_estimation/runs/8pd297a9' target=\"_blank\">glorious-grass-205</a></strong> to <a href='https://wandb.ai/technumber/animal_pose_estimation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/technumber/animal_pose_estimation' target=\"_blank\">https://wandb.ai/technumber/animal_pose_estimation</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/technumber/animal_pose_estimation/runs/8pd297a9' target=\"_blank\">https://wandb.ai/technumber/animal_pose_estimation/runs/8pd297a9</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/technik/anaconda3/envs/pytorchdlcourseproject/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /home/technik/coding/pycharm/pytorch_course_animal_pose_estimation/pose_estimation/cats/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "/home/technik/anaconda3/envs/pytorchdlcourseproject/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (18) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "\n",
      "  | Name   | Type                      | Params\n",
      "-----------------------------------------------------\n",
      "0 | model  | ConvolutionalPoseMachines | 40.2 M\n",
      "1 | loss   | MSELoss                   | 0     \n",
      "2 | metric | PCK                       | 0     \n",
      "-----------------------------------------------------\n",
      "40.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "40.2 M    Total params\n",
      "160.820   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfc855c7f14442daaed5a2a3e2b997d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technik/anaconda3/envs/pytorchdlcourseproject/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([8, 16, 45, 45])) that is different to the input size (torch.Size([7, 8, 16, 45, 45])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85d22e3d75714566b00a1213bd1cb615"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technik/anaconda3/envs/pytorchdlcourseproject/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([2, 16, 45, 45])) that is different to the input size (torch.Size([7, 2, 16, 45, 45])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f05e597d218847078ea5435cb9379193"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/technik/anaconda3/envs/pytorchdlcourseproject/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "Testing: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d6bc4e013994be4b4c0eb81628aeb30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss            11160.8759765625\n",
      "       test_metric          0.0520833320915699\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "\n",
    "\n",
    "train(cfg)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpytorchcondaf04cb2303bb94659b54446e023c3cb62",
   "display_name": "Python 3.8.2 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
